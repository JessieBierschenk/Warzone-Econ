---
title: "Assignment 1"
output:
  html_document:
    df_print: paged
date: "2023-02-07"
---

```{r warning = FALSE, message = FALSE, include = FALSE}
library(tidyverse)
library(lubridate)
library(stringr)
library(rvest)
library(MASS)
library(nnet)
library(broom)
library(knitr)
library(car)
library(Stat2Data)
library(scales)
library(gridExtra)
library(grid)
library(haven)
library(zoo)
library(ggplot2)
library(plm)
library(AER)
library(stargazer)
```

# Import Data
```{r}
NL_data = read.csv("data_month_NL.csv")
GDP_data = read_dta("Region by year GDP panel.dta")
GT_NL_data = read_rds("data_NL_GT.rds")
view(NL_data)
view(GDP_data)
view(GT_NL_data)
```

# New dataset
```{r}
all_data1 = left_join(NL_data, GDP_data, by = c("year"="year", "reg"="reg"))
all_data = left_join(all_data1, GT_NL_data, by = c("year"="year", "reg"="reg", "name"="name"))
all_data=all_data %>% 
  mutate(NLI=nl_sum_4/(area_sq_km - 0.141*nl_nodata_4),NLI2 = nl_mean_4/nl_std_4, Date = as.yearmon(paste(all_data$year, all_data$month), "%Y %m"))
NL_data=NL_data %>% 
  mutate(day= "01", Date= as.Date(with(NL_data, paste(year, month, day,sep="-")), "%Y-%m-%d"))


```

In this new dataset, there will be repeated values that do not necessarily match up to the month. Any variable besides the NL information or the tw does not correspond to the given month.

This project we will be focusing on the following regions: Odeska, Sevastopilska, Krym, Mykolaivska, Khersonska	


# Area of Region

An interesting aspect of each region to note before beginning analyses is the size. In order from largest region to smallest:

1. Odeska (33,347.50 sq km)

2. Khersonska (26,656.97 sq km)

3. Krym (25,558.45 sq km)

4. Mykolaivska (24,015.76 sq km)

5. Sevastopilska (57.44 sq km)

# Sum of NL

```{r}
region_subset = subset(all_data, reg == "UA_51"|reg == "UA_40"|reg == "UA_43"|reg == "UA_48"|reg == "UA_65" )
```

```{r}
graph1_data = subset(NL_data, reg == "UA_51"|reg == "UA_40"|reg == "UA_43"|reg == "UA_48"|reg == "UA_65" )
graph1_data = drop_na(graph1_data)
lum_overtime = ggplot(graph1_data, aes(x = Date, y= nl_sum_4, color=name))+ geom_point()+labs(title= "Sum of NL Brightness Values w/ Snow Adjustment", y="Sum of NL")+ guides(color = guide_legend(title = "Region"))

lum_overtime
```
Above shows the sum of night lights after adjusted for snow for each reason. There are clear regional differences with Sevastopilska having the smallest on average sum and Odeska having the largest. These numbers tend to make sense for the most part in terms if size of the region with Odeska being the largest region and Sevastopilska being the smallest. To get a better look at these sums, we will look at each region individually.

```{r}
Odeska_sum = ggplot( data = subset(graph1_data, reg == "UA_51"), aes(x = Date, y= nl_sum_4))+ geom_line()+labs(title= "Odeska", y="Sum of NL")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

Sevastopilska_sum = ggplot( data = subset(graph1_data, reg == "UA_40"), aes(x = Date, y= nl_sum_4))+ geom_line()+labs(title= "Sevastopilska", y="Sum of NL")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

Krym_sum = ggplot( data = subset(graph1_data, reg == "UA_43"), aes(x = Date, y= nl_sum_4))+ geom_line()+labs(title= "Krym", y="Sum of NL")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

Mykolaivska_sum = ggplot( data = subset(graph1_data, reg == "UA_48"), aes(x = Date, y= nl_sum_4))+ geom_line()+labs(title= "Mykolaivska", y="Sum of NL")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

Khersonska_sum = ggplot( data = subset(graph1_data, reg == "UA_65"), aes(x = Date, y= nl_sum_4))+ geom_line()+labs(title= "Khersonska", y="Sum of NL")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

grid.arrange(Odeska_sum,Sevastopilska_sum,Krym_sum,Mykolaivska_sum,Khersonska_sum, ncol=3, top = "Sum of NL Brightness Values w/ Snow Adjustment")

  
```
This visual provides a clearer view of trends over time by region. Odeska, Mykolaivska, and Khersonska have similar trends over the course of the ten years. Both Sevastopilska and Krym gradually increase over the ten years.

# Median NL

We will now look at the median luminosity of NL in a similar manner as the sum. Medians can be informative as they are not impacted by large outliers and can give a reasonable estimate for luminosity levels in the region.

```{r}
med_lum_overtime = ggplot(graph1_data, aes(x = Date, y= nl_median_4, color=name))+ geom_point()+labs(title= "Median NL Brightness Values w/ Snow Adjustment", y="Median NL")+ guides(color = guide_legend(title = "Region"))

med_lum_overtime


#mean_lum_overtime = ggplot(graph1_data, aes(x = Date, y= nl_mean_4, color=name))+ geom_point()+labs(title= "Median NL Brightness Values w/ Snow Adjustment", y="Median NL")+ guides(color = guide_legend(title = "Region"))

#mean_lum_overtime

```
This graph provides an interesting insight as Sevastopilska showed the smallest sum of night lights in the previous visual, yet has the highest median NL values here. This trend is consistent with mean NL data. We will observe these trends on a regional basis below to better understand variations.


```{r}
Odeska_sum = ggplot( data = subset(graph1_data, reg == "UA_51"), aes(x = Date, y= nl_median_4))+ geom_line()+labs(title= "Odeska", y="Median NL")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

Sevastopilska_sum = ggplot( data = subset(graph1_data, reg == "UA_40"), aes(x = Date, y= nl_median_4))+ geom_line()+labs(title= "Sevastopilska", y="Median NL")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

Krym_sum = ggplot( data = subset(graph1_data, reg == "UA_43"), aes(x = Date, y= nl_median_4))+ geom_line()+labs(title= "Krym", y="Median NL")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

Mykolaivska_sum = ggplot( data = subset(graph1_data, reg == "UA_48"), aes(x = Date, y= nl_median_4))+ geom_line()+labs(title= "Mykolaivska", y="Median NL")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

Khersonska_sum = ggplot( data = subset(graph1_data, reg == "UA_65"), aes(x = Date, y= nl_median_4))+ geom_line()+labs(title= "Khersonska", y="Median NL")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

grid.arrange(Odeska_sum,Sevastopilska_sum,Krym_sum,Mykolaivska_sum,Khersonska_sum, ncol=3, top = "Median NL Brightness Values w/ Snow Adjustment")

  
```
Odeska, Mykolaivska, Sevastopilska, Khersonska, and Krym all show similar trends with many occurences of median of zero. Sevastopilska has a unique trend of increasing over time and barely having any occurrences of zero.


# Look at Median Sum NL per year compared to Labor Index
```{r}
agreggated_data = aggregate(cbind(nl_count_0,nl_count_4, nl_min_0, nl_min_4, nl_max_4, nl_mean_4, nl_sum_4, nl_nodata_4, nl_std_4, nl_median_4, nl_max_0, nl_mean_0, nl_sum_0, nl_nodata_0, nl_std_0, nl_median_0, tw_count, tw_n_settlements ) ~year+ reg+name+ area_sq_km, NL_data, FUN = median)
join_aggregate = left_join(agreggated_data, GT_NL_data, by = c("year"="year", "reg"="reg", "name"="name"))
join_aggregate = left_join(join_aggregate, GDP_data, by = c("year"="year", "reg"="reg"))
subset_join_agg = subset(join_aggregate, reg == "UA_51"|reg == "UA_40"|reg == "UA_43"|reg == "UA_48"|reg == "UA_65" )
# here I am combining the data by condensing the Night Light data by taking the median of each value by year
```

```{r}

labor_comp_NL = ggplot(subset_join_agg, aes(x = Labor_index, y= nl_sum_4))+ geom_point(aes(color=name))+labs(title= "Median Year Sum of NL Brightness Values w/ Snow Adjustment
vs. Labor Index", y="Median NL", x= "Labor Index") +guides(color = guide_legend(title = "Region"))

labor_comp_NL= labor_comp_NL + geom_smooth(method = "lm", se = FALSE)
labor_comp_NL
```

# Median Number of Tweets vs. Labor Index
```{r}

labor_comp_tweets = ggplot(subset_join_agg, aes(x = Labor_index, y= tw_count))+ geom_point(aes(color=name))+labs(title= "Median Tweets in Year vs. Labor Index", y="Median Number of Tweets", x= "Labor Index") +guides(color = guide_legend(title = "Region"))

labor_comp_tweets= labor_comp_tweets + geom_smooth(method = "lm", se = FALSE)
labor_comp_tweets
```

Here we have a visual of the relaionship between the median number of tweets in a year and the labor index. Overall, there appears to be a positive correlation. Clearly there are regional differences, however.

# Log median tweets and median sum of night lights in a year
```{r}
Odeska_tweets= ggplot( data = subset(graph1_data, reg == "UA_51"))+ geom_line(aes(x = Date, y= scale(nl_sum_4)))+ geom_line(aes(x = Date, y= scale(tw_count), color="Med # Tweets"))+labs(title= "Odeska", y="Sum of NL")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+guides(color = guide_legend(title = "Legend"))

Sevastopilska_tweets = ggplot( data = subset(graph1_data, reg == "UA_40"), aes(x = Date, y= nl_sum_4))+ geom_line(aes(x = Date, y= scale(nl_sum_4)))+ geom_line(aes(x = Date, y= scale(tw_count), color="Med # Tweets"))+labs(title= "Sevastopilska", y="Sum of NL")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+guides(color = guide_legend(title = "Legend"))

Krym_tweets = ggplot( data = subset(graph1_data, reg == "UA_43"), aes(x = Date, y= nl_sum_4))+ geom_line(aes(x = Date, y= scale(nl_sum_4)))+ geom_line(aes(x = Date, y= scale(tw_count), color="Med # Tweets"))+labs(title= "Krym", y="Sum of NL")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+guides(color = guide_legend(title = "Legend"))

Mykolaivska_tweets = ggplot( data = subset(graph1_data, reg == "UA_48"), aes(x = Date, y= nl_sum_4))+ geom_line(aes(x = Date, y= scale(nl_sum_4)))+ geom_line(aes(x = Date, y= scale(tw_count), color="Med # Tweets"))+labs(title= "Mykolaivska", y="Sum of NL")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+guides(color = guide_legend(title = "Legend"))

Khersonska_tweets = ggplot( data = subset(graph1_data, reg == "UA_65"), aes(x = Date, y= nl_sum_4))+ geom_line(aes(x = Date, y= scale(nl_sum_4)))+ geom_line(aes(x = Date, y= scale(tw_count), color="Med # Tweets"))+labs(title= "Khersonska", y="Sum of NL")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+guides(color = guide_legend(title = "Legend"))

#grid.arrange(Odeska_tweets,Sevastopilska_tweets,Krym_tweets,Mykolaivska_tweets,Khersonska_tweets, ncol=2, top = "Sum of NL Brightness Values w/ Snow Adjustment")
Odeska_tweets
Sevastopilska_tweets
Krym_tweets
Mykolaivska_tweets
Khersonska_tweets
  
```
For these visualizations, I have scaled two values(median tweets and median sum of night lights in a year) in order to better understand the relationship between the two. For Regions like Odeska, Krym, and Sevastopilska, there appears to be an inverse relationship with median tweets and median sum of night lights in a year. For Mykolaivska and Khersonska, there is not as clear of relationship.

# Twitter vs. GDP


```{r}
graph_exc_K_S = subset(subset_join_agg, reg != "UA_40" & reg !="UA_43", !is.na(GDP))
GDP_comp_tweets = ggplot(graph_exc_K_S, aes(x = GDP, y= tw_count))+ geom_point(aes(color=name))+labs(title= "Median Tweets in Year vs. GDP", y="Median Number of Tweets", x= "GDP") +guides(color = guide_legend(title = "Region"))

GDP_comp_tweets= GDP_comp_tweets + geom_smooth(method = "lm", se = FALSE)
GDP_comp_tweets
```

```{r}
GDP_histo = ggplot(graph_exc_K_S, aes(x = GDP)) +
  geom_histogram(fill = "white", colour = "black") +
  facet_grid(name ~ ., scales = "free")+labs(title="GDP Distributions")
GDP_histo
```

```{r}
look_outlier = subset(subset_join_agg, GDP >250000)
```
These outliers were all collected in 2021. Now we will look at the distribution without the outliers.


```{r}
GDP_histo1 = ggplot(subset(graph_exc_K_S, GDP<250000), aes(x = GDP)) +
  geom_histogram(fill = "white", colour = "black") +
  facet_grid(name ~ ., scales = "free")+labs(title="GDP Distributions")
GDP_histo1
```




```{r}
Odeska_GDP_tweets= ggplot( data = subset(subset_join_agg, reg == "UA_51"))+ geom_line(aes(x = year, y= scale(GDP)))+ geom_line(aes(x = year, y= scale(tw_count), color="Med # Tweets"))+labs(title= "Odeska", y=" ")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+guides(color = guide_legend(title = "Legend"))

Mykolaivska_GDP_tweets = ggplot( data = subset(subset_join_agg, reg == "UA_48"), aes(x = year, y= GDP))+ geom_line(aes(x = year, y= scale(GDP)))+ geom_line(aes(x = year, y= scale(tw_count), color="Med # Tweets"))+labs(title= "Mykolaivska", y=" ")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+guides(color = guide_legend(title = "Legend"))

Khersonska_GDP_tweets = ggplot( data = subset(subset_join_agg, reg == "UA_65"), aes(x = year, y= GDP))+ geom_line(aes(x = year, y= scale(GDP)))+ geom_line(aes(x = year, y= scale(tw_count), color="Med # Tweets"))+labs(title= "Khersonska", y=" ")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+guides(color = guide_legend(title = "Legend"))

grid.arrange(Odeska_GDP_tweets, Mykolaivska_GDP_tweets, Khersonska_GDP_tweets, ncol=2, top = "GDP vs. Median # Tweets")

  
```

There is a lot of missingness in data for GDP for Sevastopilska and Krym, so these regions were not included in this visualization. Above is the scaled values of Median number of tweets in a year and GDP of the year. A scaled value is used in order to better visualize this relationship.


# Tweets vs. Emigration Index

```{r}

emig_comp_tweets = ggplot(subset_join_agg, aes(x = Emigration_index, y= tw_count))+ geom_point(aes(color=name))+labs(title= "Median Tweets in Year vs. Emigration Index", y="Median Number of Tweets", x= "Emigration Index") +guides(color = guide_legend(title = "Region"))

emig_comp_tweets= emig_comp_tweets + geom_smooth(method = "lm", se = FALSE)
emig_comp_tweets
```
There is positive relationship with the emigration index and number of tweets and clear trend differences by region.

```{r}
Odeska_Em_tweet = ggplot( data = subset(subset_join_agg, reg == "UA_51"), aes(x = Emigration_index, y= tw_count))+ geom_line()+labs(title= "Odeska", y="Median # Tweets", x = "Emigration Index")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

Sevastopilska_Em_tweet = ggplot( data = subset(subset_join_agg, reg == "UA_40"), aes(x = Emigration_index, y= tw_count))+ geom_line()+labs(title= "Sevastopilska", y="Median # Tweets", x = "Emigration Index")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

Krym_Em_tweet = ggplot( data = subset(subset_join_agg, reg == "UA_43"), aes(x = Emigration_index, y= tw_count))+ geom_line()+labs(title= "Krym", y="Median # Tweets", x = "Emigration Index")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

Mykolaivska_Em_tweet = ggplot( data = subset(subset_join_agg, reg == "UA_48"), aes(x = Emigration_index, y= tw_count))+ geom_line()+labs(title= "Mykolaivska", y="Median # Tweets", x = "Emigration Index")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

Khersonska_Em_tweet = ggplot( data = subset(subset_join_agg, reg == "UA_65"), aes(x = Emigration_index, y= tw_count))+ geom_line()+labs(title= "Khersonska", y="Median # Tweets", x = "Emigration Index")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

grid.arrange(Odeska_Em_tweet,Sevastopilska_Em_tweet,Krym_Em_tweet,Mykolaivska_Em_tweet,Khersonska_Em_tweet, ncol=3, top = "Median number number of tweets in year vs. Emigraiton index")

  
  
```
The correlation between median number of tweets varies according to region. For many of the regions, there appears to be a positive trend.




# Fixed Effect Models

The fixed effect model is a special version of a linear regression model that can capture variation due to endogenous sources. From the EDA, it is clear that year and region differences or associated with variation not explained by the given data. For this reason, I will create a two-way fixed effect model that controls for oblast and time.

```{r}
all_data_FE = all_data %>% 
  mutate(Log_GDP = log(GDP))
all_data_FE = subset(all_data_FE, reg == "UA_51"|reg == "UA_40"|reg == "UA_43"|reg == "UA_48"|reg == "UA_65" )

### Unit FE Model
NL_fe_mod <- plm(Log_GDP ~ NLI+nl_sum_4+nl_median_4+Labor_index+tw_count+MBA_degree_index,
                 data = all_data_FE,
                 index = c("name", "year"),
                 model = "within", 
                 effect="twoways")
summary(NL_fe_mod)
tidy(NL_fe_mod)
coeftest(NL_fe_mod, vcov = vcovHC, type = "HC1")
```

```{r}
# Unit FE == OLS with dummies for Units
NL_lm_mod <- lm(Log_GDP ~ NLI + name +as.factor(year)+ nl_sum_4+nl_median_4+Labor_index, data = all_data_FE)
tidy(NL_lm_mod)
```


```{r}
# Arranging results for presentation
model_se <- list(sqrt(diag(vcovHC(NL_fe_mod, type = "HC1"))),
                 sqrt(diag(vcovHC(NL_lm_mod, type = "HC1"))),
                 sqrt(diag(vcovHC(NL_tefe_mod, type = "HC1"))),
                 sqrt(diag(vcovHC(NL_TU_lm_mod, type = "HC1"))))
```

```{r}

# output latex table (type = "html" for HTML/CSS code)
# stargazer(NL_fe_mod, NL_lm_mod, NL_tefe_mod, NL_TU_lm_mod,
#           digits = 3,
#           header = FALSE,
#           type = "html",
#           se = model_se,
#           title = "Linear Panel Regression Models of GDP and Nightlights",
#           model.numbers = FALSE,
#           column.labels = c("(1)", "(2)", "(3)", "(4)"),
#           out = "table.htm")
```

